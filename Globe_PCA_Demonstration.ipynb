{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1RlY4JslWzaFhjOrvhBWQ3n0zf5JgoHNi",
      "authorship_tag": "ABX9TyM1+xrH+UIyElZ8C5UwkaNH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhuckvale/voice/blob/main/Globe_PCA_Demonstration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Demonstrate FreeVC with Deep-Speaker embedding trained on Globe sample dataset\n"
      ],
      "metadata": {
        "id": "X27TugmoT8JC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "zg4jNYOrQ7Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!pip3 install torch torchaudio torchvision torchtext torchdata webrtcvad\n",
        "!rm -rf FreeVC\n",
        "!git clone https://github.com/OlaWod/FreeVC.git\n",
        "%cd FreeVC\n",
        "!pwd"
      ],
      "metadata": {
        "id": "gdZTkcu0ZcTb",
        "outputId": "5e72532b-588b-4c77-9698-15d0a1f74ef1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.11.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting webrtcvad\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.11.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: webrtcvad\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp311-cp311-linux_x86_64.whl size=73498 sha256=aebb7a8ce0df9b2ee0db0255ee8a64ff6905880ef3d33358773e89717a1c3a96\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/65/3f/292d0b656be33d1c801831201c74b5f68f41a2ae465ff2ee2f\n",
            "Successfully built webrtcvad\n",
            "Installing collected packages: webrtcvad, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchtext, torchdata\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchdata-0.11.0 torchtext-0.18.0 webrtcvad-2.0.10\n",
            "Cloning into 'FreeVC'...\n",
            "remote: Enumerating objects: 135, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 135 (delta 45), reused 27 (delta 27), pack-reused 59 (from 2)\u001b[K\n",
            "Receiving objects: 100% (135/135), 15.28 MiB | 22.55 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n",
            "/content/FreeVC\n",
            "/content/FreeVC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Set up Python environment"
      ],
      "metadata": {
        "id": "g77V9Qr9PhM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import HBox, VBox, Layout\n",
        "from IPython.display import Audio\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "RmB1BijFUIz7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load the FreeVC model and weights trained on Globe"
      ],
      "metadata": {
        "id": "dCjfiJ3HPlCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf voice\n",
        "!git clone https://github.com/mhuckvale/voice.git\n",
        "\n",
        "%cd /content/FreeVC\n",
        "!cp /content/FreeVC/voice/FreeVC/freevc.py .\n",
        "!mkdir checkpoints\n",
        "!cp /content/FreeVC/voice/FreeVC/checkpoints/*.pt* checkpoints\n",
        "\n",
        "# download the voice conversion model\n",
        "!wget -O checkpoints/Globe10k_200000.pth https://avatartherapy.co.uk/download/Globe10k_200000.pth\n",
        "\n",
        "# download wavlm\n",
        "!wget -O wavlm/WavLM-Large.pt https://avatartherapy.co.uk/download/WavLM-Large.pt\n",
        "\n",
        "# use FreeVC to apply speaker embedding to an audio file\n",
        "import os\n",
        "from types import SimpleNamespace\n",
        "from freevc import FreeVC\n",
        "\n",
        "args = SimpleNamespace()\n",
        "args.hpfile=\"configs/freevc.json\"\n",
        "args.ptfile=\"checkpoints/Globe10k_200000.pth\"\n",
        "args.spfile='checkpoints/pretrained_bak_5805000.pt'\n",
        "args.outdir=\"output\"\n",
        "print(args)\n",
        "\n",
        "os.makedirs(args.outdir, exist_ok=True)\n",
        "freevc=FreeVC()\n",
        "freevc.load(args)"
      ],
      "metadata": {
        "id": "ZoJKST9uPD9I",
        "outputId": "d72370bf-b7a1-4ebe-a204-7937ac0d1986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'voice'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 36 (delta 8), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (36/36), 16.18 MiB | 7.63 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "/content/FreeVC\n",
            "checkpoints/Globe10k_200000.pth: Not a directory\n",
            "--2025-05-01 14:03:47--  https://avatartherapy.co.uk/download/WavLM-Large.pt\n",
            "Resolving avatartherapy.co.uk (avatartherapy.co.uk)... 185.151.30.205, 2a07:7800::205\n",
            "Connecting to avatartherapy.co.uk (avatartherapy.co.uk)|185.151.30.205|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1261965425 (1.2G)\n",
            "Saving to: ‘wavlm/WavLM-Large.pt’\n",
            "\n",
            "wavlm/WavLM-Large.p  23%[===>                ] 287.53M  31.3MB/s    in 10s     \n",
            "\n",
            "2025-05-01 14:03:58 (28.4 MB/s) - Read error at byte 301495752/1261965425 (Connection reset by peer). Retrying.\n",
            "\n",
            "--2025-05-01 14:03:59--  (try: 2)  https://avatartherapy.co.uk/download/WavLM-Large.pt\n",
            "Connecting to avatartherapy.co.uk (avatartherapy.co.uk)|185.151.30.205|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 1261965425 (1.2G), 960469673 (916M) remaining\n",
            "Saving to: ‘wavlm/WavLM-Large.pt’\n",
            "\n",
            "wavlm/WavLM-Large.p 100%[++++===============>]   1.17G  31.1MB/s    in 31s     \n",
            "\n",
            "2025-05-01 14:04:31 (29.5 MB/s) - ‘wavlm/WavLM-Large.pt’ saved [1261965425/1261965425]\n",
            "\n",
            "namespace(hpfile='configs/freevc.json', ptfile='checkpoints/Globe10k_200000.pth', spfile='checkpoints/pretrained_bak_5805000.pt', outdir='output')\n",
            "Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7fffbff8be6b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mfreevc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFreeVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mfreevc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/FreeVC/freevc.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading checkpoint...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading WavLM for content...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FreeVC/utils.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(checkpoint_path, model, optimizer, strict)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m   \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m   \u001b[0mcheckpoint_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Load scaling factors and PCA loadings for VQ parameters"
      ],
      "metadata": {
        "id": "mm4dG4D6QBEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/FreeVC/voice/FreeVC/globe-params-scale.txt .\n",
        "!cp /content/FreeVC/voice/FreeVC/globe-params-pca.txt .\n",
        "\n",
        "\n",
        "# VQ parameter scaling\n",
        "norm=pd.read_csv(\"globe-params-scale.txt\")\n",
        "print(norm)\n",
        "# VQ parameter PCA\n",
        "components=pd.read_csv(\"globe-params-pca.txt\")\n",
        "print(components)\n",
        "\n"
      ],
      "metadata": {
        "id": "u2DTQpIIU4g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Calculate the VQ parameters from principal components"
      ],
      "metadata": {
        "id": "P8Obmni0QFWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_vqparams(pca):\n",
        "    pvalues=[0]*len(norm.index)\n",
        "    for i,value in enumerate(pca):\n",
        "        for j in range(len(norm.index)):\n",
        "            pvalues[j] = pvalues[j] + pca[i] * components.iloc[i,j]\n",
        "    #print(pvalues)\n",
        "    return(pvalues)"
      ],
      "metadata": {
        "id": "OImBRxF6OWVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Set up sliders for each VQ parameter"
      ],
      "metadata": {
        "id": "qPCjaLutQJ0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a set of sliders for each parameter\n",
        "params=[]\n",
        "param_sliders=[]\n",
        "for index, row in norm.iterrows():\n",
        "    name=row['PARAMETER']\n",
        "    params.append(name)\n",
        "    mean=row['SHIFT']\n",
        "    sd=row['SCALE']\n",
        "    param_sliders.append(widgets.FloatSlider(value=mean,min=mean-3*sd,max=mean+3*sd,step=sd/10,description=name+':',readout_format='.2f'))"
      ],
      "metadata": {
        "id": "t6nWNniWOaMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Function to update VQ parameter sliders given PCA"
      ],
      "metadata": {
        "id": "7NHWTIGFQN5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params(pca):\n",
        "    pvalues = calculate_vqparams(pca)\n",
        "    for j in range(len(norm.index)):\n",
        "        mean=norm['SHIFT'][j]\n",
        "        sd=norm['SCALE'][j]\n",
        "        param_sliders[j].value=mean+sd*pvalues[j]"
      ],
      "metadata": {
        "id": "T8az2l8HOeOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Use MLP to predict speaker embedding from VQ parameters"
      ],
      "metadata": {
        "id": "ZjaqhXDYQSHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use trained MLP to convert vq embedding to FreeVC speaker embedding\n",
        "!cp /content/FreeVC/voice/FreeVC/mlp.py .\n",
        "!cp /content/FreeVC/voice/FreeVC/globevqnorm2xvec.mlp .\n",
        "\n",
        "from mlp import MLP\n",
        "mlp=MLP()\n",
        "mlp.load(\"globevqnorm2xvec.mlp\")\n",
        "#\n",
        "def predict_speaker(params):\n",
        "    #print(params)\n",
        "    embedding=mlp.forward(params)\n",
        "    #print(embedding)\n",
        "    return(embedding)\n",
        "\n"
      ],
      "metadata": {
        "id": "x6m4JHIGOiRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Build sliders for first 6 principal components of VQ params"
      ],
      "metadata": {
        "id": "M89ReoW-QVti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to respond to change in value of slider\n",
        "def value_change(change):\n",
        "    slider=change['owner']\n",
        "    pcatext.value=slider.description + '=' + str(change['new'])\n",
        "    values=[]\n",
        "    for slider in pca_sliders:\n",
        "        values.append(slider.value)\n",
        "    update_params(values)\n",
        "\n",
        "# build sliders\n",
        "pca_sliders=[]\n",
        "for i in range(6):\n",
        "    slider=widgets.FloatSlider(value=0.,min=-5.0,max=5.0,step=0.5,description='PCA'+str(i+1),readout_format='.2f')\n",
        "    slider.observe(value_change,names='value')\n",
        "    pca_sliders.append(slider)\n",
        "pcatext=widgets.Text(value='',placeholder='',description='Status:',disabled=False)\n",
        "\n",
        "# reset button\n",
        "reset_button = widgets.Button(description='Reset')\n",
        "def on_reset(b):\n",
        "    for slider in pca_sliders:\n",
        "        slider.value=0.1\n",
        "        slider.value=0\n",
        "reset_button.on_click(on_reset)\n",
        "\n",
        "# PCA Synthesis button\n",
        "pcago_button = widgets.Button(description='Go PCA')\n",
        "def on_pcago(b):\n",
        "    runconversion(0)\n",
        "pcago_button.on_click(on_pcago)\n",
        "\n",
        "# VQ Synthesis button\n",
        "vqgo_button = widgets.Button(description='Go VQ')\n",
        "def on_vqgo(b):\n",
        "    runconversion(1)\n",
        "vqgo_button.on_click(on_vqgo)"
      ],
      "metadata": {
        "id": "AusR78YrOnLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Run voice conversion from VQ or PCA values"
      ],
      "metadata": {
        "id": "P-4rtzdSQaiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/FreeVC/voice/FreeVC/*.wav .\n",
        "\n",
        "# select audio\n",
        "import glob\n",
        "wavlist=glob.glob(\"*.wav\")\n",
        "sndlist=[ s.replace(\".wav\",\"\") for s in wavlist]\n",
        "options=list(zip(sndlist,wavlist))\n",
        "wavselect=widgets.Dropdown(options=options,value='whitelight.wav',description=\"Audio\",disabled=False)\n",
        "\n",
        "from IPython.display import Audio, clear_output\n",
        "output4 = widgets.Output(layout={'border': '1px solid black'})\n",
        "\n",
        "def runconversion(isvq=0):\n",
        "    with output4:\n",
        "        if isvq:\n",
        "            # get VQ params directly from sliders\n",
        "            vqparams=[]\n",
        "            for j,slider in enumerate(param_sliders):\n",
        "                mean=norm['SHIFT'][j]\n",
        "                sd=norm['SCALE'][j]\n",
        "                val=(slider.value-mean)/sd\n",
        "                vqparams.append(val)\n",
        "        else:\n",
        "            # get  PCA slider values and calculate VQ params\n",
        "            pcavalues=[]\n",
        "            for slider in pca_sliders:\n",
        "                pcavalues.append(slider.value)\n",
        "            # create the VQ parameters from the PCA\n",
        "            pcatext.value=\"calculate vq params\"\n",
        "            vqparams=calculate_vqparams(pcavalues)\n",
        "        #print(vqparams)\n",
        "        # calculate the speaker embedding using the MLP model\n",
        "        pcatext.value=\"calculate speaker embedding\"\n",
        "        speaker_embedding=predict_speaker(vqparams)\n",
        "        # perform conversion\n",
        "        pcatext.value=\"voice conversion started\"\n",
        "        freevc.convert(wavselect.value,speaker_embedding,'out.wav')\n",
        "        # replay audio\n",
        "        pcatext.value=\"replaying\"\n",
        "        clear_output(wait=True)\n",
        "        player = Audio('output/out.wav',autoplay=True)\n",
        "        display(player)\n",
        "\n",
        "output4"
      ],
      "metadata": {
        "id": "TjqxXOa2Orxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Create the user interface"
      ],
      "metadata": {
        "id": "GHSsFQnOQiCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# layout\n",
        "title1=widgets.HTML(\"<h2>Raw Voice Parameters</h2>\")\n",
        "title2=widgets.HTML(\"<h2>Principal Components</h2>\")\n",
        "box_layout = Layout(display='flex', flex_flow='column', align_items='center',border='solid', width='50%')\n",
        "\n",
        "HBox(children=[\n",
        "    VBox([title2,*pca_sliders,wavselect,HBox([reset_button,pcago_button])],layout=box_layout),\n",
        "    VBox([title1,*param_sliders,HBox([reset_button,vqgo_button])],layout=box_layout)\n",
        "])\n"
      ],
      "metadata": {
        "id": "tZ0LEkXGOvE4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}